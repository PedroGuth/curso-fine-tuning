{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ **M√≥dulo 1: Por que Fine Tuning √© como ensinar um cachorro novos truques?**\n",
    "\n",
    "## **Aula 1.1: O que √© Fine Tuning e por que voc√™ precisa saber**\n",
    "\n",
    "---\n",
    "\n",
    "### **T√°, mas o que √© Fine Tuning?**\n",
    "\n",
    "Imagine que voc√™ tem um cachorro super inteligente (tipo um border collie). Ele j√° sabe sentar, deitar, dar a pata, buscar a bolinha. Mas voc√™ quer que ele aprenda a **pegar o jornal da porta** ou **fechar a porta do quarto**.\n",
    "\n",
    "**Fine Tuning √© exatamente isso!** Voc√™ pega uma IA que j√° √© inteligente e ensina ela a fazer coisas espec√≠ficas para o seu caso de uso.\n",
    "\n",
    "**Por que Fine Tuning √© importante?**\n",
    "\n",
    "√â como ter um funcion√°rio experiente vs um estagi√°rio:\n",
    "- **IA gen√©rica**: Sabe de tudo um pouco, mas n√£o √© especialista em nada\n",
    "- **IA com Fine Tuning**: Especialista no seu dom√≠nio espec√≠fico\n",
    "\n",
    "---\n",
    "\n",
    "**üñºÔ∏è Sugest√£o de imagem**: Cachorro aprendendo truque espec√≠fico vs cachorro gen√©rico\n",
    "\n",
    "### **Setup Inicial - Preparando o Terreno**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Comparando IA Gen√©rica vs IA Especializada**\n",
    "\n",
    "Vamos ver na pr√°tica a diferen√ßa entre uma IA gen√©rica e uma especializada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico: IA gen√©rica vs especializada\n",
    "\n",
    "print(\"ü§ñ EXEMPLO: IA Gen√©rica vs Especializada\\n\")\n",
    "\n",
    "# Pergunta espec√≠fica sobre um produto\n",
    "pergunta = \"Qual √© a diferen√ßa entre o iPhone 15 Pro e o iPhone 15?\"\n",
    "\n",
    "print(f\"‚ùì Pergunta: {pergunta}\\n\")\n",
    "\n",
    "# Resposta da IA gen√©rica (simulada)\n",
    "resposta_generica = \"\"\"\n",
    "O iPhone 15 Pro e o iPhone 15 s√£o smartphones da Apple. \n",
    "Ambos s√£o bons telefones com recursos similares.\n",
    "\"\"\"\n",
    "\n",
    "# Resposta da IA especializada (simulada)\n",
    "resposta_especializada = \"\"\"\n",
    "üì± iPhone 15 Pro vs iPhone 15:\n",
    "\n",
    "üîπ **Tela**: Pro tem 6.1\" vs 6.1\" (mas Pro tem ProMotion 120Hz)\n",
    "üîπ **Chip**: Pro tem A17 Pro vs A16 Bionic\n",
    "üîπ **C√¢mera**: Pro tem 3 c√¢meras (48MP + 12MP + 12MP) vs 2 c√¢meras (48MP + 12MP)\n",
    "üîπ **Material**: Pro tem tit√¢nio vs alum√≠nio\n",
    "üîπ **Pre√ßo**: Pro custa R$ 8.999 vs R$ 6.999\n",
    "\n",
    "üí° **Recomenda√ß√£o**: Se voc√™ √© fot√≥grafo ou gamer, v√° de Pro. Se √© uso b√°sico, iPhone 15 √© suficiente.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ü§ñ IA GEN√âRICA:\")\n",
    "print(resposta_generica)\n",
    "print(\"\\nü§ñ IA ESPECIALIZADA (com Fine Tuning):\")\n",
    "print(resposta_especializada)\n",
    "\n",
    "print(\"\\nüí° Viu a diferen√ßa? A IA especializada d√° respostas muito mais √∫teis e espec√≠ficas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Quando usar Fine Tuning vs outras t√©cnicas**\n",
    "\n",
    "√â como escolher a ferramenta certa para o trabalho. Cada t√©cnica tem seu momento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara√ß√£o das t√©cnicas de IA\n",
    "\n",
    "tecnicas = {\n",
    "    \"Prompt Engineering\": {\n",
    "        \"descricao\": \"Como dar instru√ß√µes claras para a IA\",\n",
    "        \"analogia\": \"Como dar instru√ß√µes para um gar√ßom\",\n",
    "        \"quando_usar\": \"Tarefas simples, respostas r√°pidas\",\n",
    "        \"custo\": \"Gratuito\",\n",
    "        \"esforco\": \"Baixo\"\n",
    "    },\n",
    "    \"RAG (Retrieval Augmented Generation)\": {\n",
    "        \"descricao\": \"IA que consulta documentos para responder\",\n",
    "        \"analogia\": \"Como um bibliotec√°rio que consulta livros\",\n",
    "        \"quando_usar\": \"Informa√ß√µes espec√≠ficas, documentos\",\n",
    "        \"custo\": \"Baixo\",\n",
    "        \"esforco\": \"M√©dio\"\n",
    "    },\n",
    "    \"Fine Tuning\": {\n",
    "        \"descricao\": \"Treinar a IA para tarefas espec√≠ficas\",\n",
    "        \"analogia\": \"Como ensinar um funcion√°rio experiente\",\n",
    "        \"quando_usar\": \"Tarefas complexas, dom√≠nio espec√≠fico\",\n",
    "        \"custo\": \"M√©dio\",\n",
    "        \"esforco\": \"Alto\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üõ†Ô∏è COMPARA√á√ÉO DAS T√âCNICAS\\n\")\n",
    "\n",
    "for tecnica, info in tecnicas.items():\n",
    "    print(f\"üîπ {tecnica}\")\n",
    "    print(f\"   üìù {info['descricao']}\")\n",
    "    print(f\"   üé≠ {info['analogia']}\")\n",
    "    print(f\"   üéØ {info['quando_usar']}\")\n",
    "    print(f\"   üí∞ Custo: {info['custo']}\")\n",
    "    print(f\"   ‚ö° Esfor√ßo: {info['esforco']}\")\n",
    "    print()\n",
    "\n",
    "print(\"üí° Fine Tuning √© a t√©cnica mais poderosa, mas tamb√©m a mais complexa!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Exemplo Pr√°tico: Carregando um modelo base**\n",
    "\n",
    "Vamos ver como √© um modelo \"antes\" do fine tuning. √â como ver um funcion√°rio antes do treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes necess√°rias\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando um modelo pequeno para demonstra√ß√£o\n",
    "print(\"ü§ñ Carregando modelo base...\")\n",
    "\n",
    "try:\n",
    "    # Usando um modelo pequeno para demonstra√ß√£o\n",
    "    model_name = \"microsoft/DialoGPT-small\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    print(f\"‚úÖ Modelo carregado: {model_name}\")\n",
    "    print(f\"üìä Par√¢metros: {model.num_parameters():,}\")\n",
    "    \n",
    "    # Teste simples\n",
    "    input_text = \"Ol√°, como voc√™ est√°?\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_length=50, \n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    resposta = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"\\nüí¨ Resposta do modelo base:\")\n",
    "    print(f\"   Input: {input_text}\")\n",
    "    print(f\"   Output: {resposta}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erro ao carregar modelo: {e}\")\n",
    "    print(\"üí° N√£o se preocupe, vamos continuar com exemplos simulados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Visualizando o processo de Fine Tuning**\n",
    "\n",
    "Vamos criar uma visualiza√ß√£o para entender melhor o processo. √â como ver o antes e depois de um treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando visualiza√ß√£o do processo de Fine Tuning\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Antes do Fine Tuning\n",
    "ax1.set_title('ü§ñ ANTES: Modelo Gen√©rico', fontsize=14, fontweight='bold')\n",
    "ax1.text(0.5, 0.8, 'IA Gen√©rica\\n(Conhecimento Geral)', ha='center', va='center', \n",
    "         fontsize=12, bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue'))\n",
    "ax1.text(0.5, 0.4, '‚ùì Pergunta Espec√≠fica\\n\\n‚ùå Resposta Gen√©rica\\n\\nüí≠ \"N√£o sei muito sobre isso\"', \n",
    "         ha='center', va='center', fontsize=10, \n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcoral'))\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axis('off')\n",
    "\n",
    "# Depois do Fine Tuning\n",
    "ax2.set_title('üéØ DEPOIS: Modelo Especializado', fontsize=14, fontweight='bold')\n",
    "ax2.text(0.5, 0.8, 'IA Especializada\\n(Conhecimento Espec√≠fico)', ha='center', va='center', \n",
    "         fontsize=12, bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen'))\n",
    "ax2.text(0.5, 0.4, '‚ùì Pergunta Espec√≠fica\\n\\n‚úÖ Resposta Especializada\\n\\nüí° \"Aqui est√° a resposta detalhada\"', \n",
    "         ha='center', va='center', fontsize=10, \n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen'))\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Fine Tuning transforma uma IA gen√©rica em uma especialista no seu dom√≠nio!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Teste R√°pido**\n",
    "\n",
    "Vamos testar seu entendimento sobre Fine Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste r√°pido de entendimento\n",
    "print(\"üß™ TESTE R√ÅPIDO\\n\")\n",
    "\n",
    "perguntas = [\n",
    "    {\n",
    "        \"pergunta\": \"Qual t√©cnica voc√™ usaria para responder perguntas sobre documentos espec√≠ficos da sua empresa?\",\n",
    "        \"opcoes\": [\"A) Prompt Engineering\", \"B) RAG\", \"C) Fine Tuning\"],\n",
    "        \"resposta\": \"B\",\n",
    "        \"explicacao\": \"RAG √© perfeito para consultar documentos espec√≠ficos!\"\n",
    "    },\n",
    "    {\n",
    "        \"pergunta\": \"Qual t√©cnica voc√™ usaria para criar um assistente especializado em vendas de produtos espec√≠ficos?\",\n",
    "        \"opcoes\": [\"A) Prompt Engineering\", \"B) RAG\", \"C) Fine Tuning\"],\n",
    "        \"resposta\": \"C\",\n",
    "        \"explicacao\": \"Fine Tuning √© ideal para dom√≠nios espec√≠ficos como vendas!\"\n",
    "    },\n",
    "    {\n",
    "        \"pergunta\": \"Qual t√©cnica √© mais r√°pida de implementar?\",\n",
    "        \"opcoes\": [\"A) Prompt Engineering\", \"B) RAG\", \"C) Fine Tuning\"],\n",
    "        \"resposta\": \"A\",\n",
    "        \"explicacao\": \"Prompt Engineering √© a mais r√°pida, mas menos poderosa!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, q in enumerate(perguntas, 1):\n",
    "    print(f\"‚ùì {i}. {q['pergunta']}\")\n",
    "    for opcao in q['opcoes']:\n",
    "        print(f\"   {opcao}\")\n",
    "    print(f\"üí° Resposta: {q['resposta']} - {q['explicacao']}\")\n",
    "    print()\n",
    "\n",
    "print(\"üéâ Parab√©ns! Voc√™ j√° entende as diferen√ßas b√°sicas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Desafio do M√≥dulo**\n",
    "\n",
    "Agora √© sua vez de pensar em um caso de uso espec√≠fico para Fine Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desafio do m√≥dulo\n",
    "print(\"üéØ DESAFIO DO M√ìDULO\\n\")\n",
    "\n",
    "print(\"Pense em um caso de uso espec√≠fico para Fine Tuning:\")\n",
    "print(\"\\nüìù Escreva aqui sua ideia:\")\n",
    "print(\"   - Qual seria o dom√≠nio espec√≠fico?\")\n",
    "print(\"   - Que tipo de perguntas a IA responderia?\")\n",
    "print(\"   - Por que Fine Tuning seria melhor que RAG ou Prompt Engineering?\")\n",
    "\n",
    "print(\"\\nüí° Exemplos de ideias:\")\n",
    "exemplos = [\n",
    "    \"Assistente de vendas para uma loja espec√≠fica\",\n",
    "    \"Tutor de matem√°tica com metodologia personalizada\",\n",
    "    \"Analista de sentimentos para coment√°rios de redes sociais\",\n",
    "    \"Assistente jur√≠dico especializado em uma √°rea espec√≠fica\",\n",
    "    \"Coach de fitness com sua metodologia\"\n",
    "]\n",
    "\n",
    "for i, exemplo in enumerate(exemplos, 1):\n",
    "    print(f\"   {i}. {exemplo}\")\n",
    "\n",
    "print(\"\\nüöÄ No pr√≥ximo m√≥dulo, vamos aprender a preparar os dados para o Fine Tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üéâ M√≥dulo 1 Conclu√≠do!**\n",
    "\n",
    "### **O que aprendemos:**\n",
    "\n",
    "‚úÖ **Fine Tuning √© como ensinar um funcion√°rio experiente**  \n",
    "‚úÖ **Diferen√ßas entre Prompt Engineering, RAG e Fine Tuning**  \n",
    "‚úÖ **Quando usar cada t√©cnica**  \n",
    "‚úÖ **Vantagens da IA especializada**  \n",
    "‚úÖ **Processo visual do Fine Tuning**\n",
    "\n",
    "### **Pr√≥ximos Passos:**\n",
    "\n",
    "üöÄ **M√≥dulo 2**: Preparando os dados como um chef prepara ingredientes  \n",
    "üöÄ **M√≥dulo 3**: Escolhendo o modelo certo como escolher um carro  \n",
    "üöÄ **M√≥dulo 4**: Treinando como um personal trainer  \n",
    "üöÄ **M√≥dulo 5**: Avaliando como um professor corrige prova  \n",
    "üöÄ **M√≥dulo 6**: Deploy como abrir um restaurante\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Dica do Instrutor**: Fine Tuning √© como cozinhar - voc√™ precisa dos ingredientes certos (dados) antes de come√ßar a cozinhar (treinar)! üòÑ\n",
    "\n",
    "**üöÄ Pr√≥ximo m√≥dulo**: Vamos preparar os dados para o treinamento!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
